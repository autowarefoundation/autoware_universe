<launch>
  <arg name="build_only" default="false" description="shutdown node after TensorRT engine file is built"/>
  <arg name="debug_mode" default="true" description="debug mode"/>
  <arg name="param_path" default="$(find-pkg-share autoware_camera_streampetr)/config/tensorrt_stream_petr.param.yaml"/>
  <arg name="model_path" default="$(env HOME)/autoware_data/camera_streampetr"/>

  <node pkg="autoware_camera_streampetr" exec="autoware_camera_streampetr_node" name="stream_petr" output="screen">
    <param from="$(var param_path)" allow_substs="true"/>
    <param name="build_only" value="$(var build_only)"/>
    <param name="debug_mode" value="$(var debug_mode)"/>
    <param name="model_params.backbone_path" value="$(var model_path)/simplify_extract_img_feat.onnx"/>
    <param name="model_params.head_path" value="$(var model_path)/simplify_pts_head_memory.onnx"/>
    <param name="model_params.position_embedding_path" value="$(var model_path)/simplify_position_embedding.onnx"/>

    <remap from="~/input/kinematic_state" to="/localization/kinematic_state"/>

    <!-- Image of ~/input/camerai will be the ith image in the model input -->
    <remap from="~/input/camera0/camera_info" to="/sensing/camera/camera0/camera_info"/>
    <remap from="~/input/camera1/camera_info" to="/sensing/camera/camera1/camera_info"/>
    <remap from="~/input/camera2/camera_info" to="/sensing/camera/camera2/camera_info"/>
    <remap from="~/input/camera3/camera_info" to="/sensing/camera/camera3/camera_info"/>
    <remap from="~/input/camera4/camera_info" to="/sensing/camera/camera4/camera_info"/>
    <remap from="~/input/camera5/camera_info" to="/sensing/camera/camera5/camera_info"/>

    <!--  Uncomment if you want to use uncompressed images, and set is_compressed_image to false -->
    <!-- <remap from="~/input/camera0/image" to="/sensing/camera/camera0/image_rect_color"/>
    <remap from="~/input/camera1/image" to="/sensing/camera/camera1/image_rect_color"/>
    <remap from="~/input/camera2/image" to="/sensing/camera/camera2/image_rect_color"/>
    <remap from="~/input/camera3/image" to="/sensing/camera/camera3/image_rect_color"/>
    <remap from="~/input/camera4/image" to="/sensing/camera/camera4/image_rect_color"/>
    <remap from="~/input/camera5/image" to="/sensing/camera/camera5/image_rect_color"/>  -->

    <!--  Uncomment if you want to use compressed images, and set is_compressed_image to true -->
    <remap from="~/input/camera0/image/compressed" to="/sensing/camera/camera0/image_rect_color/compressed"/>
    <remap from="~/input/camera1/image/compressed" to="/sensing/camera/camera1/image_rect_color/compressed"/>
    <remap from="~/input/camera2/image/compressed" to="/sensing/camera/camera2/image_rect_color/compressed"/>
    <remap from="~/input/camera3/image/compressed" to="/sensing/camera/camera3/image_rect_color/compressed"/>
    <remap from="~/input/camera4/image/compressed" to="/sensing/camera/camera4/image_rect_color/compressed"/>
    <remap from="~/input/camera5/image/compressed" to="/sensing/camera/camera5/image_rect_color/compressed"/>

    <!-- Maximum allowed time difference for camera image sync in seconds-->
    <param name="max_camera_time_diff" value="0.15"/>
    <!-- The forward pass begins once every anchor camera topic reaches. Choose this as the camera that causes the shortest differnce in min and max timestamp between cameras-->
    <param name="anchor_camera_id" value="0"/>
    <!-- Whether the input image is compressed. -->
    <param name="is_compressed_image" value="true"/>
    <!-- Whether the input image is distorted. -->
    <param name="is_distorted_image" value="false"/>
    <!-- If is_distorted_image=true,factor to downsample the image by during undistortion. Makes undistortion faster than using full scale-->
    <param name="downsample_factor" value="0.5"/>
    <!-- Whether to use multithreading for handling image callbacks-->
    <param name="multithreading" value="true"/>
  </node>
</launch>
